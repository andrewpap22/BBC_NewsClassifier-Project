{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create features from the raw text so we can train the machine learning models. The steps followed are:\n",
    "\n",
    "* **Text Cleaning and Preparation**: cleaning of special characters, downcasing, punctuation signs. possessive pronouns and stop words removal and lemmatization.\n",
    "* **Label coding**: creation of a dictionary to map each category to a code.\n",
    "* **Train-test split**: to test the models on unseen data.\n",
    "* **Text representation**: use of TF-IDF scores to represent text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all we'll load the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = \"/home/andrewpap22/Desktop/DataScience-testDir/data.pickle\"\n",
    "\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name                                            Content  Category  \\\n",
       "0   001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "1   002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...  business   \n",
       "2   003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...  business   \n",
       "3   004.txt  High fuel prices hit BA's profits\\n\\nBritish A...  business   \n",
       "4   005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in...  business   \n",
       "\n",
       "  Complete_Filename  id  News_length  \n",
       "0  001.txt-business   1         2559  \n",
       "1  002.txt-business   1         2251  \n",
       "2  003.txt-business   1         1551  \n",
       "3  004.txt-business   1         2411  \n",
       "4  005.txt-business   1         1569  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize one sample news content:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yukos unit buyer faces loan claim\\n\\nThe owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan.\\n\\nState-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos\\' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets. Rosneft already faces a similar $540m repayment demand from foreign banks. Legal experts said Rosneft\\'s purchase of Yugansk would include such obligations. \"The pledged assets are with Rosneft, so it will have to pay real money to the creditors to avoid seizure of Yugansk assets,\" said Moscow-based US lawyer Jamie Firestone, who is not connected to the case. Menatep Group\\'s managing director Tim Osborne told the Reuters news agency: \"If they default, we will fight them where the rule of law exists under the international arbitration clauses of the credit.\"\\n\\nRosneft officials were unavailable for comment. But the company has said it intends to take action against Menatep to recover some of the tax claims and debts owed by Yugansk. Yukos had filed for bankruptcy protection in a US court in an attempt to prevent the forced sale of its main production arm. The sale went ahead in December and Yugansk was sold to a little-known shell company which in turn was bought by Rosneft. Yukos claims its downfall was punishment for the political ambitions of its founder Mikhail Khodorkovsky and has vowed to sue any participant in the sale.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2]['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text cleaning and preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Special character cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the following special characters:\n",
    "\n",
    "* \\r\n",
    "* \\n\n",
    "* \\ before possessive pronouns (government's = government\\'s)\n",
    "* \\ before possessive pronouns 2 (Yukos' = Yukos\\')\n",
    "* \" when quoting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\r and \\n\n",
    "df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mr Greenspan's\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regarding 3rd and 4th bullet, although it seems there is a special character, it won't affect us since it is not a real character:\n",
    "\n",
    "text = \"Mr Greenspan\\'s\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \" when quoting text\n",
    "df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Upcase/Downcase\n",
    "\n",
    "We'll downcase the texts because we want, for example, Football and football to be the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing the text\n",
    "df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Punctuation signs\n",
    "\n",
    "Punctuation signs won't have any predicting power, so we'll just get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this we are messing up with some numbers, but it's no problem since we aren't expecting any predicting power from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. Possessive pronouns\n",
    "\n",
    "We'll also remove possessive pronoun terminations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5. Stemming and Lemmatization \n",
    "\n",
    "*Since stemming can produce output words that don't exist, we'll only use a lemmatization process at this moment. Lemmatization takes into consideration the morphological analysis of the words and returns words that do exist, so it will be more useful for us.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/andrewpap22/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/andrewpap22/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading punkt and wordnet from NLTK\n",
    "nltk.download('punkt')\n",
    "print(\"------------------------------------------------------------\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN order to lemmatize, we have to iterate through every word:\n",
    "\n",
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['Content_Parsed_4']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_Parsed_5'] = lemmatized_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although lemmatization doesn't work perfectly in all cases (as can be seen in the example below), it can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 Stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/andrewpap22/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english'))\n",
    "stop_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StopWord eating a meal'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To remove the stop words, we'll handle a regular expression only detecting whole words, as seen in the following example:\n",
    "\n",
    "example = \"me eating a meal\"\n",
    "word = \"me\"\n",
    "\n",
    "# The regular expression is:\n",
    "regex = r\"\\b\" + word + r\"\\b\"  # we need to build it like that to work properly\n",
    "\n",
    "re.sub(regex, \"StopWord\", example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now loop through all the stop words:\n",
    "\n",
    "df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We have some dobule/triple spaces between words because of the replacements. However, it's not a problem because we'll tokenize by the spaces later.*\n",
    "\n",
    "*As an example, we'll show an original news article and its modifications throughout the process:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mixed signals from French economy\\n\\nThe French economy picked up speed at the end of 2004, official figures show - but still looks set to have fallen short of the government\\'s hopes.\\n\\nAccording to state statistics body INSEE, growth for the three months to December was a seasonally-adjusted 0.7-0.8%, ahead of the 0.6% forecast. If confirmed, that would be the best quarterly showing since early 2002. It leaves GDP up 2.3% for the full year, but short of the 2.5% which the French government had predicted.\\n\\nDespite the apparent shortfall in annual economic growth, the good quarterly figures - a so-called \"flash estimate\" - mark a continuing trend of improving indicators for the health of the French economy. The government is reiterating a 2.5% target for 2005, while the European Central Bank is making positive noises for the 12-nation eurozone as a whole. Also on Friday, France\\'s industrial output for December was released, showing 0.7% growth. \"The numbers are good,\" said David Naude, economist at Deutsche Bank. \"They send a positive signal of a rebound in output... and open the way for a continuation in that trend into the New Year.\" Service sector activity improved in January, hitting a seven-month high. But unemployment remains high at about 10%.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[22]['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Special character cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mixed signals from French economy  The French economy picked up speed at the end of 2004, official figures show - but still looks set to have fallen short of the government's hopes.  According to state statistics body INSEE, growth for the three months to December was a seasonally-adjusted 0.7-0.8%, ahead of the 0.6% forecast. If confirmed, that would be the best quarterly showing since early 2002. It leaves GDP up 2.3% for the full year, but short of the 2.5% which the French government had predicted.  Despite the apparent shortfall in annual economic growth, the good quarterly figures - a so-called flash estimate - mark a continuing trend of improving indicators for the health of the French economy. The government is reiterating a 2.5% target for 2005, while the European Central Bank is making positive noises for the 12-nation eurozone as a whole. Also on Friday, France's industrial output for December was released, showing 0.7% growth. The numbers are good, said David Naude, economist at Deutsche Bank. They send a positive signal of a rebound in output... and open the way for a continuation in that trend into the New Year. Service sector activity improved in January, hitting a seven-month high. But unemployment remains high at about 10%.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[22]['Content_Parsed_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Uppercase/Downcase :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mixed signals from french economy  the french economy picked up speed at the end of 2004, official figures show - but still looks set to have fallen short of the government's hopes.  according to state statistics body insee, growth for the three months to december was a seasonally-adjusted 0.7-0.8%, ahead of the 0.6% forecast. if confirmed, that would be the best quarterly showing since early 2002. it leaves gdp up 2.3% for the full year, but short of the 2.5% which the french government had predicted.  despite the apparent shortfall in annual economic growth, the good quarterly figures - a so-called flash estimate - mark a continuing trend of improving indicators for the health of the french economy. the government is reiterating a 2.5% target for 2005, while the european central bank is making positive noises for the 12-nation eurozone as a whole. also on friday, france's industrial output for december was released, showing 0.7% growth. the numbers are good, said david naude, economist at deutsche bank. they send a positive signal of a rebound in output... and open the way for a continuation in that trend into the new year. service sector activity improved in january, hitting a seven-month high. but unemployment remains high at about 10%.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[22]['Content_Parsed_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Punctuation signs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mixed signals from french economy  the french economy picked up speed at the end of 2004 official figures show - but still looks set to have fallen short of the government's hopes  according to state statistics body insee growth for the three months to december was a seasonally-adjusted 07-08% ahead of the 06% forecast if confirmed that would be the best quarterly showing since early 2002 it leaves gdp up 23% for the full year but short of the 25% which the french government had predicted  despite the apparent shortfall in annual economic growth the good quarterly figures - a so-called flash estimate - mark a continuing trend of improving indicators for the health of the french economy the government is reiterating a 25% target for 2005 while the european central bank is making positive noises for the 12-nation eurozone as a whole also on friday france's industrial output for december was released showing 07% growth the numbers are good said david naude economist at deutsche bank they send a positive signal of a rebound in output and open the way for a continuation in that trend into the new year service sector activity improved in january hitting a seven-month high but unemployment remains high at about 10%\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[22]['Content_Parsed_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Possessive pronouns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mixed signals from french economy  the french economy picked up speed at the end of 2004 official figures show - but still looks set to have fallen short of the government hopes  according to state statistics body insee growth for the three months to december was a seasonally-adjusted 07-08% ahead of the 06% forecast if confirmed that would be the best quarterly showing since early 2002 it leaves gdp up 23% for the full year but short of the 25% which the french government had predicted  despite the apparent shortfall in annual economic growth the good quarterly figures - a so-called flash estimate - mark a continuing trend of improving indicators for the health of the french economy the government is reiterating a 25% target for 2005 while the european central bank is making positive noises for the 12-nation eurozone as a whole also on friday france industrial output for december was released showing 07% growth the numbers are good said david naude economist at deutsche bank they send a positive signal of a rebound in output and open the way for a continuation in that trend into the new year service sector activity improved in january hitting a seven-month high but unemployment remains high at about 10%'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[22]['Content_Parsed_4'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Stemming and Lemmatization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mix signal from french economy  the french economy pick up speed at the end of 2004 official figure show - but still look set to have fall short of the government hop  accord to state statistics body insee growth for the three months to december be a seasonally-adjusted 07-08% ahead of the 06% forecast if confirm that would be the best quarterly show since early 2002 it leave gdp up 23% for the full year but short of the 25% which the french government have predict  despite the apparent shortfall in annual economic growth the good quarterly figure - a so-called flash estimate - mark a continue trend of improve indicators for the health of the french economy the government be reiterate a 25% target for 2005 while the european central bank be make positive noise for the 12-nation eurozone as a whole also on friday france industrial output for december be release show 07% growth the number be good say david naude economist at deutsche bank they send a positive signal of a rebound in output and open the way for a continuation in that trend into the new year service sector activity improve in january hit a seven-month high but unemployment remain high at about 10%'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[22]['Content_Parsed_5'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Stop Words:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mix signal  french economy   french economy pick  speed   end  2004 official figure show -  still look set   fall short   government hop  accord  state statistics body insee growth   three months  december   seasonally-adjusted 07-08% ahead   06% forecast  confirm  would   best quarterly show since early 2002  leave gdp  23%   full year  short   25%   french government  predict  despite  apparent shortfall  annual economic growth  good quarterly figure -  -called flash estimate - mark  continue trend  improve indicators   health   french economy  government  reiterate  25% target  2005   european central bank  make positive noise   12-nation eurozone   whole also  friday france industrial output  december  release show 07% growth  number  good say david naude economist  deutsche bank  send  positive signal   rebound  output  open  way   continuation   trend   new year service sector activity improve  january hit  seven-month high  unemployment remain high   10%'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[22]['Content_Parsed_6'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Content_Parsed_1</th>\n",
       "      <th>Content_Parsed_2</th>\n",
       "      <th>Content_Parsed_3</th>\n",
       "      <th>Content_Parsed_4</th>\n",
       "      <th>Content_Parsed_5</th>\n",
       "      <th>Content_Parsed_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2559</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name                                            Content  Category  \\\n",
       "0   001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...  business   \n",
       "\n",
       "  Complete_Filename  id  News_length  \\\n",
       "0  001.txt-business   1         2559   \n",
       "\n",
       "                                    Content_Parsed_1  \\\n",
       "0  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_2  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_3  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_4  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_5  \\\n",
       "0  ad sales boost time warner profit  quarterly p...   \n",
       "\n",
       "                                    Content_Parsed_6  \n",
       "0  ad sales boost time warner profit  quarterly p...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can delete the intermediate coliumns: \n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = [\"File_Name\", \"Category\", \"Complete_Filename\", \"Content\", \"Content_Parsed_6\"]\n",
    "df = df[list_columns]\n",
    "\n",
    "df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>dollar gain  greenspan speech   dollar  hit  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>yukos unit buyer face loan claim   owners  emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>high fuel price hit ba profit  british airways...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>pernod takeover talk lift domecq  share  uk dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name  Category Complete_Filename  \\\n",
       "0   001.txt  business  001.txt-business   \n",
       "1   002.txt  business  002.txt-business   \n",
       "2   003.txt  business  003.txt-business   \n",
       "3   004.txt  business  004.txt-business   \n",
       "4   005.txt  business  005.txt-business   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                      Content_Parsed  \n",
       "0  ad sales boost time warner profit  quarterly p...  \n",
       "1  dollar gain  greenspan speech   dollar  hit  h...  \n",
       "2  yukos unit buyer face loan claim   owners  emb...  \n",
       "3  high fuel price hit ba profit  british airways...  \n",
       "4  pernod takeover talk lift domecq  share  uk dr...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Label coding\n",
    "\n",
    "*We'll create a dictionary with the label codification:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>ad sales boost time warner profit  quarterly p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>dollar gain  greenspan speech   dollar  hit  h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>yukos unit buyer face loan claim   owners  emb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>high fuel price hit ba profit  british airways...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>pernod takeover talk lift domecq  share  uk dr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name  Category Complete_Filename  \\\n",
       "0   001.txt  business  001.txt-business   \n",
       "1   002.txt  business  002.txt-business   \n",
       "2   003.txt  business  003.txt-business   \n",
       "3   004.txt  business  004.txt-business   \n",
       "4   005.txt  business  005.txt-business   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                      Content_Parsed  Category_Code  \n",
       "0  ad sales boost time warner profit  quarterly p...              0  \n",
       "1  dollar gain  greenspan speech   dollar  hit  h...              0  \n",
       "2  yukos unit buyer face loan claim   owners  emb...              0  \n",
       "3  high fuel price hit ba profit  british airways...              0  \n",
       "4  pernod takeover talk lift domecq  share  uk dr...              0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_codes = {\n",
    "    'business': 0,\n",
    "    'entertainment': 1,\n",
    "    'politics': 2,\n",
    "    'sport': 3,\n",
    "    'tech': 4\n",
    "}\n",
    "\n",
    "# Category mapping\n",
    "df['Category_Code'] = df['Category']\n",
    "df = df.replace({'Category_Code':category_codes})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train - Test split\n",
    "\n",
    "**We'll set apart a test set to prove the quality of our models. We'll do Cross Validation in the train set in order to tune the hyperparameters and then test performance on the unseen data of the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Content_Parsed'], \n",
    "                                                    df['Category_Code'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have much observations (only 2.225), we'll choose a test set size of 20% of the full dataset as described in the project definition document.\n",
    "\n",
    "# Text representation : \n",
    "\n",
    "We have various options:\n",
    "\n",
    "* Count Vectors as features\n",
    "* TF-IDF Vectors as features\n",
    "* Word Embeddings as features\n",
    "* Text / NLP based features\n",
    "* Topic Models as features\n",
    "\n",
    "We'll use **TF-IDF Vectors** as features, since it's requested from the project, classification part to be done in that particular text representation\n",
    "\n",
    "We have to define the different parameters:\n",
    "\n",
    "* ngram_range: We want to consider both unigrams and bigrams.\n",
    "* max_df: When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
    "* min_df: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "* max_features: If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "\n",
    "See TfidfVectorizer? for further detail.\n",
    "\n",
    "It needs to be mentioned that we are implicitly scaling our data when representing it as TF-IDF features with the argument norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen these values as a first approximation. Since the models that we develop later have a very good predictive power, we'll stick to these values. But it has to be mentioned that different combinations could be tried in order to improve even more the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780, 300)\n",
      "(445, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we have fitted and then transformed the training set, but we have **only transformed the test set**.\n",
    "\n",
    "We can use the Chi squared test in order to see what unigrams and bigrams are most correlated with each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business' category:\n",
      "  . Most correlated unigrams:\n",
      ". price\n",
      ". market\n",
      ". economy\n",
      ". growth\n",
      ". bank\n",
      "  . Most correlated bigrams:\n",
      ". last year\n",
      ". year old\n",
      "\n",
      "# 'entertainment' category:\n",
      "  . Most correlated unigrams:\n",
      ". music\n",
      ". best\n",
      ". star\n",
      ". award\n",
      ". film\n",
      "  . Most correlated bigrams:\n",
      ". mr blair\n",
      ". prime minister\n",
      "\n",
      "# 'politics' category:\n",
      "  . Most correlated unigrams:\n",
      ". minister\n",
      ". blair\n",
      ". election\n",
      ". party\n",
      ". labour\n",
      "  . Most correlated bigrams:\n",
      ". prime minister\n",
      ". mr blair\n",
      "\n",
      "# 'sport' category:\n",
      "  . Most correlated unigrams:\n",
      ". win\n",
      ". side\n",
      ". game\n",
      ". team\n",
      ". match\n",
      "  . Most correlated bigrams:\n",
      ". say mr\n",
      ". year old\n",
      "\n",
      "# 'tech' category:\n",
      "  . Most correlated unigrams:\n",
      ". digital\n",
      ". software\n",
      ". computer\n",
      ". technology\n",
      ". users\n",
      "  . Most correlated bigrams:\n",
      ". year old\n",
      ". say mr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the unigrams correspond well to their category. However, bigrams do not. If we get the bigrams in our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tell bbc', 'last year', 'mr blair', 'prime minister', 'year old', 'say mr']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are only six. This means the unigrams have more correlation with the category than the bigrams, and since we're restricting the number of features to the most representative 300, only a few bigrams are being considered.\n",
    "\n",
    "We'll save our files here and move on to the next notebook, the Classification one! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "with open('Pickles/X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "    \n",
    "# X_test    \n",
    "with open('Pickles/X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# y_train\n",
    "with open('Pickles/y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(y_train, output)\n",
    "    \n",
    "# y_test\n",
    "with open('Pickles/y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(y_test, output)\n",
    "    \n",
    "# df\n",
    "with open('Pickles/df.pickle', 'wb') as output:\n",
    "    pickle.dump(df, output)\n",
    "    \n",
    "# features_train\n",
    "with open('Pickles/features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('Pickles/labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('Pickles/features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "\n",
    "# labels_test\n",
    "with open('Pickles/labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('Pickles/tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
